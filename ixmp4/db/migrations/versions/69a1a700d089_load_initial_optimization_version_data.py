# type: ignore
"""Load initial opt version data

Revision ID: 69a1a700d089
Revises: e189ffe6a65e
Create Date: 2025-09-05 19:21:14.796068

"""

import enum
import logging
from datetime import datetime

import sqlalchemy as sa
from alembic import op

logger = logging.getLogger(__name__)

# Revision identifiers, used by Alembic.
revision = "69a1a700d089"
down_revision = "e189ffe6a65e"
branch_labels = None
depends_on = None


class Operation(int, enum.Enum):
    INSERT = 0
    UPDATE = 1
    DELETE = 2


initial_transaction_id = 1
tables = [
    ("opt_sca", "opt_sca_version"),
    ("opt_idx", "opt_idx_version"),
    ("opt_idx_data", "opt_idx_data_version"),
    ("opt_par", "opt_par_version"),
    ("opt_par_idx_association", "opt_par_idx_association_version"),
    ("opt_tab", "opt_tab_version"),
    ("opt_tab_idx_association", "opt_tab_idx_association_version"),
    ("opt_equ", "opt_equ_version"),
    ("opt_equ_idx_association", "opt_equ_idx_association_version"),
    ("opt_var", "opt_var_version"),
    ("opt_var_idx_association", "opt_var_idx_association_version"),
]

tabledata_chunksize = 10000


def generate_initial_version_data(
    data_table_name: str, version_table_name: str, transaction_id: int
):
    """Generate initial version data for a given data table."""
    logging.info(
        f"Copying initial data from '{data_table_name}' "
        f"to '{version_table_name}' table ..."
    )

    conn = op.get_bind()

    if conn is not None:
        version_table = sa.Table(
            version_table_name,
            sa.MetaData(),
            autoload_with=conn,
        )

        data_table = sa.Table(
            data_table_name,
            sa.MetaData(),
            autoload_with=conn,
        )

        partitions = (
            conn.execute(
                sa.select(data_table).execution_options(yield_per=tabledata_chunksize)
            )
            .mappings()
            .partitions(tabledata_chunksize)
        )
        for res in partitions:
            initial_versions = [
                {
                    **row,
                    "transaction_id": transaction_id,
                    "end_transaction_id": None,
                    "operation_type": Operation.INSERT,
                }
                for row in res
            ]
            op.bulk_insert(version_table, initial_versions)
    else:
        logging.warning("No database connection available.")


def upgrade():
    logging.info(
        f"Creating initial transaction object with ID {initial_transaction_id} ..."
    )

    conn = op.get_bind()

    if conn is not None:
        if conn.dialect.name != "postgresql":
            logging.info("Not running on postgres database, skipping migration.")
            return

        # reflect transaction table
        transaction_table = sa.Table(
            "transaction",
            sa.MetaData(),
            autoload_with=conn,
        )

        # Check if any transactions already exist
        res = conn.execute(sa.select(transaction_table)).all()
        if len(res) > 0:
            logging.warning(
                "Database already contains transactions. "
                "Skipping creation of initial version "
                "data to avoid corrupting the database."
            )
            return

        # Create initial transaction
        op.bulk_insert(
            transaction_table,
            [
                {
                    "id": initial_transaction_id,
                    "remote_addr": "",
                    "issued_at": datetime.now(),
                },
            ],
        )

    else:
        logging.warning("No database connection available.")

    for data_table_name, version_table_name in tables:
        generate_initial_version_data(
            data_table_name,
            version_table_name,
            initial_transaction_id,
        )


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    pass
    # ### end Alembic commands ###
